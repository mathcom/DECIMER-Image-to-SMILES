{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bf5901-99cd-49cb-ae94-b42805e3ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3ca54f-df8a-44f5-ae62-7ffd1b91d8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 09:37:03.720367: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-04 09:37:03.720391: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-04 09:37:03.720395: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-04 09:37:03.723444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = \"0\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1aa9c2-66ff-445b-a211-96c69c4a5fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 09:37:04.373168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-04 09:37:04.388064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-04 09:37:04.388152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "#Setting up memory growth\n",
    "for gpu in gpus:\n",
    "\ttf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e45bf55-5c07-400c-aa88-3a101437efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['XLA_FLAGS']=\"--xla_gpu_cuda_data_dir=/home/descartes/miniconda3/envs/DECIMERv1/lib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7686b9d-7df3-47e0-9460-3cad8c7a053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network import I2S_Model, I2S_Data, I2S_Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66abffe1-9795-45fc-b8b6-3fc6b3b43839",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c08bd7-e111-41d8-86e0-a245a223c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Configs:\n",
    "    ## Inputs\n",
    "    filename_training = 'training_data_original'\n",
    "    #filename_training = 'training_data_randepict'\n",
    "    filepath_training = os.path.join('Data', f'{filename_training}.csv')\n",
    "    image_dir = os.path.join('Data', filename_training)\n",
    "    ## Setting up training parameters, found after optimizing\n",
    "    epochs = 200\n",
    "    batch_size = 64\n",
    "    buffer_size = 1000\n",
    "    embedding_dim = 600\n",
    "    units = 1024\n",
    "    ## Here, we are using Inception V3 as base so the feature shape is set to 2048 and the attention shape is set to 64\n",
    "    features_shape = 2048\n",
    "    attention_features_shape = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecb617b-9ade-4126-b129-4332c4acb720",
   "metadata": {},
   "source": [
    "# Load a Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0586c94-90f7-460d-b71e-238dab9f3503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 09:37:04.439506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-04 09:37:04.439612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-04 09:37:04.439661: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-04 09:37:04.497881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-04 09:37:04.497969: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-04 09:37:04.498025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-04 09:37:04.498067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22258 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Data  2604 All data  2604\n",
      "<start>CCC=C=CCC)PC63C<end> Data/training_data_original/CDK_Depict_40_9.png\n",
      "<start>C=NC=CN=CPC5=N9<end> Data/training_data_original/CDK_Depict_5_28.png\n",
      "<start>C=CCN=CN)SN<end> Data/training_data_original/CDK_Depict_47_200.png\n",
      "<start>O=CNC=O)C=COCC=CC=CC=C6)))))))))N5<end> Data/training_data_original/CDK_Depict_42_86.png\n",
      "<start>CCC=NCC=N)NCCNCC)C6=N))))))))=CS5<end> Data/training_data_original/CDK_Depict_38_218.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 09:37:05.517148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n"
     ]
    }
   ],
   "source": [
    "img_name_train, img_name_val, smi_train, smi_val, image_features_extract_model = I2S_Data.data_loader(Configs.filepath_training, Configs.image_dir, train_test_split=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7845712-db8f-452e-a558-69d68c1edfaa",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a520d70-9f44-45c6-b256-df16163f4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 69\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('Network', 'tokenizer.pkl'), \"rb\") as fin:\n",
    "    tokenizer = pickle.load(fin)\n",
    "\n",
    "vocabs = tokenizer.word_index.keys()\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"vocab_size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106c0cf2-a5bc-49e7-835a-5f150d5cf76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length: 60\n"
     ]
    }
   ],
   "source": [
    "seq_train = tokenizer.texts_to_sequences([I2S_Data.split_by_vocabulary(smi, vocabs) for smi in smi_train])\n",
    "cap_train = tf.keras.preprocessing.sequence.pad_sequences(seq_train, padding='post')\n",
    "max_length = I2S_Data.calc_max_length(seq_train)\n",
    "print(f\"max_length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ba4fa2-f7a0-4f3a-8469-191b7bb025e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = I2S_Utils.create_dataset(img_name_train, cap_train, Configs.batch_size, Configs.buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c495d2-88dc-44b7-adf2-8a066a377eb8",
   "metadata": {},
   "source": [
    "# Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9d74ba-6c86-4e4d-858c-8d6df08b4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = I2S_Model.CNN_Encoder(Configs.embedding_dim)\n",
    "decoder = I2S_Model.RNN_Decoder(Configs.embedding_dim, Configs.units, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c130e31-9c39-41ee-8763-462bcfe5584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network Parameters\n",
    "#optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.00051)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1364eb77-5202-4969-9a45-f327c32f7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "\tmask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "\tloss_ = loss_object(real, pred)\n",
    "\n",
    "\tmask = tf.cast(mask, dtype=loss_.dtype)\n",
    "\tloss_ *= mask\n",
    "\n",
    "\treturn tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de6a54-d254-425d-8b5d-81db2593e422",
   "metadata": {},
   "source": [
    "# Load the foundation model (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa911a7-01e0-415e-8eff-8676c7d3d277",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = I2S_Utils.Trainer(encoder, decoder, optimizer, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73e9aa5e-30db-4274-95bf-329f0d09341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_checkpoint(os.path.join('Trained_Models', 'Trained_Models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2bf6ce-cc90-49d7-8d24-7ed8ccfa2d2a",
   "metadata": {},
   "source": [
    "# Initialize a checkpoint manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b062eb7-4832-40aa-936f-3f3c80ad7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up path to save checkpoint\n",
    "checkpoint_path = os.path.join('ckpt', Configs.filename_training)\n",
    "ckpt = tf.train.Checkpoint(encoder=encoder, decoder=decoder, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87381ba4-2e4f-4195-a90f-11dd2c03d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "## Loading checkpoint to last saved\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "\tckpt.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\tstart_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
    "print(start_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12895467-c3a1-4c46-b08a-415ea9250a60",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "705ac07f-d70b-4746-a487-5be9811029cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_steps: 40\n"
     ]
    }
   ],
   "source": [
    "num_steps = len(img_name_train) // Configs.batch_size\n",
    "print(f\"num_steps: {num_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b5317ab-b52c-4ae4-b11a-91bb29e9d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation dataset\n",
    "do_validation = False\n",
    "\n",
    "if do_validation:\n",
    "    val_smiles, val_img_name = I2S_Data.data_loader_eval(os.path.join('Data', 'validation_data.csv'), os.path.join('Data', 'validation_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2354ca0-e9da-4eff-9dee-bd02d59ca3fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [2025/01/04 09:38:11] Epoch: 1    Loss: 1.280049   (40 sec)\n",
      ">>> [2025/01/04 09:38:18] Epoch: 2    Loss: 0.685794   (7 sec)\n",
      ">>> [2025/01/04 09:38:21] Epoch: 3    Loss: 0.608453   (3 sec)\n",
      ">>> [2025/01/04 09:38:24] Epoch: 4    Loss: 0.568957   (3 sec)\n",
      ">>> [2025/01/04 09:38:28] Epoch: 5    Loss: 0.539069   (3 sec)\n",
      ">>> [2025/01/04 09:38:31] Epoch: 6    Loss: 0.514472   (3 sec)\n",
      ">>> [2025/01/04 09:38:36] Epoch: 7    Loss: 0.493284   (5 sec)\n",
      ">>> [2025/01/04 09:38:43] Epoch: 8    Loss: 0.474990   (7 sec)\n",
      ">>> [2025/01/04 09:38:50] Epoch: 9    Loss: 0.455647   (7 sec)\n",
      ">>> [2025/01/04 09:38:56] Epoch: 10    Loss: 0.439177   (7 sec)\n",
      ">>> [2025/01/04 09:39:03] Epoch: 11    Loss: 0.422073   (7 sec)\n",
      ">>> [2025/01/04 09:39:10] Epoch: 12    Loss: 0.405732   (7 sec)\n",
      ">>> [2025/01/04 09:39:16] Epoch: 13    Loss: 0.390010   (7 sec)\n",
      ">>> [2025/01/04 09:39:23] Epoch: 14    Loss: 0.372296   (7 sec)\n",
      ">>> [2025/01/04 09:39:30] Epoch: 15    Loss: 0.353713   (7 sec)\n",
      ">>> [2025/01/04 09:39:36] Epoch: 16    Loss: 0.336670   (7 sec)\n",
      ">>> [2025/01/04 09:39:43] Epoch: 17    Loss: 0.319455   (7 sec)\n",
      ">>> [2025/01/04 09:39:50] Epoch: 18    Loss: 0.303484   (7 sec)\n",
      ">>> [2025/01/04 09:39:57] Epoch: 19    Loss: 0.284786   (7 sec)\n",
      ">>> [2025/01/04 09:40:03] Epoch: 20    Loss: 0.269890   (7 sec)\n",
      ">>> [2025/01/04 09:40:10] Epoch: 21    Loss: 0.257036   (6 sec)\n",
      ">>> [2025/01/04 09:40:16] Epoch: 22    Loss: 0.240811   (7 sec)\n",
      ">>> [2025/01/04 09:40:23] Epoch: 23    Loss: 0.226985   (7 sec)\n",
      ">>> [2025/01/04 09:40:30] Epoch: 24    Loss: 0.214620   (7 sec)\n",
      ">>> [2025/01/04 09:40:37] Epoch: 25    Loss: 0.200245   (6 sec)\n",
      ">>> [2025/01/04 09:40:43] Epoch: 26    Loss: 0.186613   (7 sec)\n",
      ">>> [2025/01/04 09:40:50] Epoch: 27    Loss: 0.175508   (7 sec)\n",
      ">>> [2025/01/04 09:40:57] Epoch: 28    Loss: 0.162609   (7 sec)\n",
      ">>> [2025/01/04 09:41:04] Epoch: 29    Loss: 0.150203   (7 sec)\n",
      ">>> [2025/01/04 09:41:10] Epoch: 30    Loss: 0.141468   (6 sec)\n",
      ">>> [2025/01/04 09:41:17] Epoch: 31    Loss: 0.132931   (7 sec)\n",
      ">>> [2025/01/04 09:41:23] Epoch: 32    Loss: 0.124525   (7 sec)\n",
      ">>> [2025/01/04 09:41:30] Epoch: 33    Loss: 0.113926   (7 sec)\n",
      ">>> [2025/01/04 09:41:37] Epoch: 34    Loss: 0.104872   (6 sec)\n",
      ">>> [2025/01/04 09:41:43] Epoch: 35    Loss: 0.097462   (7 sec)\n",
      ">>> [2025/01/04 09:41:50] Epoch: 36    Loss: 0.090951   (7 sec)\n",
      ">>> [2025/01/04 09:41:57] Epoch: 37    Loss: 0.083365   (7 sec)\n",
      ">>> [2025/01/04 09:42:04] Epoch: 38    Loss: 0.077364   (7 sec)\n",
      ">>> [2025/01/04 09:42:10] Epoch: 39    Loss: 0.075137   (7 sec)\n",
      ">>> [2025/01/04 09:42:17] Epoch: 40    Loss: 0.070288   (7 sec)\n",
      ">>> [2025/01/04 09:42:24] Epoch: 41    Loss: 0.064409   (7 sec)\n",
      ">>> [2025/01/04 09:42:30] Epoch: 42    Loss: 0.059960   (7 sec)\n",
      ">>> [2025/01/04 09:42:37] Epoch: 43    Loss: 0.055210   (6 sec)\n",
      ">>> [2025/01/04 09:42:44] Epoch: 44    Loss: 0.053667   (7 sec)\n",
      ">>> [2025/01/04 09:42:50] Epoch: 45    Loss: 0.052833   (7 sec)\n",
      ">>> [2025/01/04 09:42:57] Epoch: 46    Loss: 0.046792   (7 sec)\n",
      ">>> [2025/01/04 09:43:04] Epoch: 47    Loss: 0.044619   (7 sec)\n",
      ">>> [2025/01/04 09:43:10] Epoch: 48    Loss: 0.044653   (6 sec)\n",
      ">>> [2025/01/04 09:43:17] Epoch: 49    Loss: 0.044055   (7 sec)\n",
      ">>> [2025/01/04 09:43:24] Epoch: 50    Loss: 0.038846   (7 sec)\n",
      ">>> [2025/01/04 09:43:30] Epoch: 51    Loss: 0.039209   (7 sec)\n",
      ">>> [2025/01/04 09:43:37] Epoch: 52    Loss: 0.038636   (7 sec)\n",
      ">>> [2025/01/04 09:43:44] Epoch: 53    Loss: 0.035282   (7 sec)\n",
      ">>> [2025/01/04 09:43:50] Epoch: 54    Loss: 0.034814   (7 sec)\n",
      ">>> [2025/01/04 09:43:57] Epoch: 55    Loss: 0.034329   (7 sec)\n",
      ">>> [2025/01/04 09:44:04] Epoch: 56    Loss: 0.035500   (7 sec)\n",
      ">>> [2025/01/04 09:44:10] Epoch: 57    Loss: 0.035648   (6 sec)\n",
      ">>> [2025/01/04 09:44:17] Epoch: 58    Loss: 0.034310   (7 sec)\n",
      ">>> [2025/01/04 09:44:24] Epoch: 59    Loss: 0.029368   (7 sec)\n",
      ">>> [2025/01/04 09:44:31] Epoch: 60    Loss: 0.030606   (7 sec)\n",
      ">>> [2025/01/04 09:44:37] Epoch: 61    Loss: 0.030602   (7 sec)\n",
      ">>> [2025/01/04 09:44:44] Epoch: 62    Loss: 0.028839   (7 sec)\n",
      ">>> [2025/01/04 09:44:51] Epoch: 63    Loss: 0.028168   (7 sec)\n",
      ">>> [2025/01/04 09:44:57] Epoch: 64    Loss: 0.028010   (7 sec)\n",
      ">>> [2025/01/04 09:45:04] Epoch: 65    Loss: 0.029615   (7 sec)\n",
      ">>> [2025/01/04 09:45:10] Epoch: 66    Loss: 0.027420   (6 sec)\n",
      ">>> [2025/01/04 09:45:17] Epoch: 67    Loss: 0.029392   (7 sec)\n",
      ">>> [2025/01/04 09:45:24] Epoch: 68    Loss: 0.026213   (7 sec)\n",
      ">>> [2025/01/04 09:45:31] Epoch: 69    Loss: 0.026217   (7 sec)\n",
      ">>> [2025/01/04 09:45:37] Epoch: 70    Loss: 0.023941   (7 sec)\n",
      ">>> [2025/01/04 09:45:43] Epoch: 71    Loss: 0.025666   (6 sec)\n",
      ">>> [2025/01/04 09:45:50] Epoch: 72    Loss: 0.024065   (7 sec)\n",
      ">>> [2025/01/04 09:45:57] Epoch: 73    Loss: 0.023119   (7 sec)\n",
      ">>> [2025/01/04 09:46:03] Epoch: 74    Loss: 0.022077   (7 sec)\n",
      ">>> [2025/01/04 09:46:10] Epoch: 75    Loss: 0.022974   (7 sec)\n",
      ">>> [2025/01/04 09:46:17] Epoch: 76    Loss: 0.022453   (7 sec)\n",
      ">>> [2025/01/04 09:46:23] Epoch: 77    Loss: 0.021761   (7 sec)\n",
      ">>> [2025/01/04 09:46:30] Epoch: 78    Loss: 0.021670   (7 sec)\n",
      ">>> [2025/01/04 09:46:37] Epoch: 79    Loss: 0.022318   (7 sec)\n",
      ">>> [2025/01/04 09:46:43] Epoch: 80    Loss: 0.024959   (6 sec)\n",
      ">>> [2025/01/04 09:46:50] Epoch: 81    Loss: 0.025441   (7 sec)\n",
      ">>> [2025/01/04 09:46:57] Epoch: 82    Loss: 0.025894   (7 sec)\n",
      ">>> [2025/01/04 09:47:03] Epoch: 83    Loss: 0.021921   (7 sec)\n",
      ">>> [2025/01/04 09:47:10] Epoch: 84    Loss: 0.022728   (6 sec)\n",
      ">>> [2025/01/04 09:47:17] Epoch: 85    Loss: 0.019238   (7 sec)\n",
      ">>> [2025/01/04 09:47:23] Epoch: 86    Loss: 0.021508   (7 sec)\n",
      ">>> [2025/01/04 09:47:30] Epoch: 87    Loss: 0.019596   (7 sec)\n",
      ">>> [2025/01/04 09:47:37] Epoch: 88    Loss: 0.018897   (7 sec)\n",
      ">>> [2025/01/04 09:47:43] Epoch: 89    Loss: 0.018228   (6 sec)\n",
      ">>> [2025/01/04 09:47:50] Epoch: 90    Loss: 0.019948   (7 sec)\n",
      ">>> [2025/01/04 09:47:57] Epoch: 91    Loss: 0.019551   (7 sec)\n",
      ">>> [2025/01/04 09:48:04] Epoch: 92    Loss: 0.020399   (7 sec)\n",
      ">>> [2025/01/04 09:48:10] Epoch: 93    Loss: 0.019148   (7 sec)\n",
      ">>> [2025/01/04 09:48:17] Epoch: 94    Loss: 0.018433   (7 sec)\n",
      ">>> [2025/01/04 09:48:24] Epoch: 95    Loss: 0.019894   (7 sec)\n",
      ">>> [2025/01/04 09:48:30] Epoch: 96    Loss: 0.018130   (7 sec)\n",
      ">>> [2025/01/04 09:48:37] Epoch: 97    Loss: 0.019864   (7 sec)\n",
      ">>> [2025/01/04 09:48:43] Epoch: 98    Loss: 0.020161   (6 sec)\n",
      ">>> [2025/01/04 09:48:50] Epoch: 99    Loss: 0.017750   (7 sec)\n",
      ">>> [2025/01/04 09:48:57] Epoch: 100    Loss: 0.016477   (7 sec)\n",
      ">>> [2025/01/04 09:49:04] Epoch: 101    Loss: 0.021986   (7 sec)\n",
      ">>> [2025/01/04 09:49:11] Epoch: 102    Loss: 0.016166   (7 sec)\n",
      ">>> [2025/01/04 09:49:17] Epoch: 103    Loss: 0.017895   (6 sec)\n",
      ">>> [2025/01/04 09:49:24] Epoch: 104    Loss: 0.019190   (7 sec)\n",
      ">>> [2025/01/04 09:49:30] Epoch: 105    Loss: 0.016478   (7 sec)\n",
      ">>> [2025/01/04 09:49:38] Epoch: 106    Loss: 0.021401   (7 sec)\n",
      ">>> [2025/01/04 09:49:44] Epoch: 107    Loss: 0.019164   (6 sec)\n",
      ">>> [2025/01/04 09:49:51] Epoch: 108    Loss: 0.016061   (7 sec)\n",
      ">>> [2025/01/04 09:49:57] Epoch: 109    Loss: 0.021092   (7 sec)\n",
      ">>> [2025/01/04 09:50:04] Epoch: 110    Loss: 0.016950   (7 sec)\n",
      ">>> [2025/01/04 09:50:11] Epoch: 111    Loss: 0.017660   (7 sec)\n",
      ">>> [2025/01/04 09:50:18] Epoch: 112    Loss: 0.016285   (7 sec)\n",
      ">>> [2025/01/04 09:50:24] Epoch: 113    Loss: 0.017046   (7 sec)\n",
      ">>> [2025/01/04 09:50:31] Epoch: 114    Loss: 0.015929   (7 sec)\n",
      ">>> [2025/01/04 09:50:38] Epoch: 115    Loss: 0.018305   (7 sec)\n",
      ">>> [2025/01/04 09:50:44] Epoch: 116    Loss: 0.015569   (6 sec)\n",
      ">>> [2025/01/04 09:50:51] Epoch: 117    Loss: 0.016448   (7 sec)\n",
      ">>> [2025/01/04 09:50:58] Epoch: 118    Loss: 0.014774   (7 sec)\n",
      ">>> [2025/01/04 09:51:04] Epoch: 119    Loss: 0.015836   (7 sec)\n",
      ">>> [2025/01/04 09:51:11] Epoch: 120    Loss: 0.015818   (7 sec)\n",
      ">>> [2025/01/04 09:51:18] Epoch: 121    Loss: 0.013764   (6 sec)\n",
      ">>> [2025/01/04 09:51:24] Epoch: 122    Loss: 0.015400   (7 sec)\n",
      ">>> [2025/01/04 09:51:31] Epoch: 123    Loss: 0.012674   (7 sec)\n",
      ">>> [2025/01/04 09:51:38] Epoch: 124    Loss: 0.015969   (7 sec)\n",
      ">>> [2025/01/04 09:51:44] Epoch: 125    Loss: 0.015575   (6 sec)\n",
      ">>> [2025/01/04 09:51:51] Epoch: 126    Loss: 0.015485   (7 sec)\n",
      ">>> [2025/01/04 09:51:58] Epoch: 127    Loss: 0.014952   (7 sec)\n",
      ">>> [2025/01/04 09:52:04] Epoch: 128    Loss: 0.016137   (7 sec)\n",
      ">>> [2025/01/04 09:52:11] Epoch: 129    Loss: 0.015024   (7 sec)\n",
      ">>> [2025/01/04 09:52:17] Epoch: 130    Loss: 0.017070   (6 sec)\n",
      ">>> [2025/01/04 09:52:24] Epoch: 131    Loss: 0.014678   (7 sec)\n",
      ">>> [2025/01/04 09:52:31] Epoch: 132    Loss: 0.016068   (7 sec)\n",
      ">>> [2025/01/04 09:52:38] Epoch: 133    Loss: 0.015716   (7 sec)\n",
      ">>> [2025/01/04 09:52:44] Epoch: 134    Loss: 0.016341   (6 sec)\n",
      ">>> [2025/01/04 09:52:51] Epoch: 135    Loss: 0.016644   (7 sec)\n",
      ">>> [2025/01/04 09:52:58] Epoch: 136    Loss: 0.013591   (7 sec)\n",
      ">>> [2025/01/04 09:53:05] Epoch: 137    Loss: 0.016036   (7 sec)\n",
      ">>> [2025/01/04 09:53:11] Epoch: 138    Loss: 0.014174   (7 sec)\n",
      ">>> [2025/01/04 09:53:18] Epoch: 139    Loss: 0.017733   (6 sec)\n",
      ">>> [2025/01/04 09:53:24] Epoch: 140    Loss: 0.016998   (7 sec)\n",
      ">>> [2025/01/04 09:53:31] Epoch: 141    Loss: 0.016152   (7 sec)\n",
      ">>> [2025/01/04 09:53:38] Epoch: 142    Loss: 0.014034   (7 sec)\n",
      ">>> [2025/01/04 09:53:44] Epoch: 143    Loss: 0.016960   (6 sec)\n",
      ">>> [2025/01/04 09:53:51] Epoch: 144    Loss: 0.015762   (7 sec)\n",
      ">>> [2025/01/04 09:53:58] Epoch: 145    Loss: 0.015250   (7 sec)\n",
      ">>> [2025/01/04 09:54:05] Epoch: 146    Loss: 0.014420   (7 sec)\n",
      ">>> [2025/01/04 09:54:11] Epoch: 147    Loss: 0.013787   (7 sec)\n",
      ">>> [2025/01/04 09:54:18] Epoch: 148    Loss: 0.013167   (6 sec)\n",
      ">>> [2025/01/04 09:54:25] Epoch: 149    Loss: 0.012277   (7 sec)\n",
      ">>> [2025/01/04 09:54:31] Epoch: 150    Loss: 0.013291   (7 sec)\n",
      ">>> [2025/01/04 09:54:38] Epoch: 151    Loss: 0.013994   (7 sec)\n",
      ">>> [2025/01/04 09:54:45] Epoch: 152    Loss: 0.011676   (7 sec)\n",
      ">>> [2025/01/04 09:54:51] Epoch: 153    Loss: 0.013026   (7 sec)\n",
      ">>> [2025/01/04 09:54:58] Epoch: 154    Loss: 0.013278   (7 sec)\n",
      ">>> [2025/01/04 09:55:05] Epoch: 155    Loss: 0.012080   (7 sec)\n",
      ">>> [2025/01/04 09:55:12] Epoch: 156    Loss: 0.012956   (7 sec)\n",
      ">>> [2025/01/04 09:55:18] Epoch: 157    Loss: 0.012951   (6 sec)\n",
      ">>> [2025/01/04 09:55:25] Epoch: 158    Loss: 0.012161   (7 sec)\n",
      ">>> [2025/01/04 09:55:32] Epoch: 159    Loss: 0.011031   (7 sec)\n",
      ">>> [2025/01/04 09:55:38] Epoch: 160    Loss: 0.014444   (7 sec)\n",
      ">>> [2025/01/04 09:55:45] Epoch: 161    Loss: 0.012371   (7 sec)\n",
      ">>> [2025/01/04 09:55:52] Epoch: 162    Loss: 0.013670   (7 sec)\n",
      ">>> [2025/01/04 09:55:59] Epoch: 163    Loss: 0.014011   (7 sec)\n",
      ">>> [2025/01/04 09:56:05] Epoch: 164    Loss: 0.012609   (7 sec)\n",
      ">>> [2025/01/04 09:56:12] Epoch: 165    Loss: 0.013039   (7 sec)\n",
      ">>> [2025/01/04 09:56:19] Epoch: 166    Loss: 0.012015   (6 sec)\n",
      ">>> [2025/01/04 09:56:25] Epoch: 167    Loss: 0.011038   (7 sec)\n",
      ">>> [2025/01/04 09:56:32] Epoch: 168    Loss: 0.010922   (7 sec)\n",
      ">>> [2025/01/04 09:56:39] Epoch: 169    Loss: 0.012498   (7 sec)\n",
      ">>> [2025/01/04 09:56:46] Epoch: 170    Loss: 0.011487   (7 sec)\n",
      ">>> [2025/01/04 09:56:52] Epoch: 171    Loss: 0.010929   (7 sec)\n",
      ">>> [2025/01/04 09:56:59] Epoch: 172    Loss: 0.010768   (7 sec)\n",
      ">>> [2025/01/04 09:57:06] Epoch: 173    Loss: 0.011062   (7 sec)\n",
      ">>> [2025/01/04 09:57:12] Epoch: 174    Loss: 0.013052   (7 sec)\n",
      ">>> [2025/01/04 09:57:19] Epoch: 175    Loss: 0.010613   (6 sec)\n",
      ">>> [2025/01/04 09:57:25] Epoch: 176    Loss: 0.013470   (7 sec)\n",
      ">>> [2025/01/04 09:57:32] Epoch: 177    Loss: 0.012407   (7 sec)\n",
      ">>> [2025/01/04 09:57:39] Epoch: 178    Loss: 0.011254   (7 sec)\n",
      ">>> [2025/01/04 09:57:46] Epoch: 179    Loss: 0.010807   (7 sec)\n",
      ">>> [2025/01/04 09:57:52] Epoch: 180    Loss: 0.012745   (6 sec)\n",
      ">>> [2025/01/04 09:57:59] Epoch: 181    Loss: 0.011935   (7 sec)\n",
      ">>> [2025/01/04 09:58:06] Epoch: 182    Loss: 0.009902   (7 sec)\n",
      ">>> [2025/01/04 09:58:12] Epoch: 183    Loss: 0.010525   (7 sec)\n",
      ">>> [2025/01/04 09:58:19] Epoch: 184    Loss: 0.011419   (6 sec)\n",
      ">>> [2025/01/04 09:58:26] Epoch: 185    Loss: 0.011770   (7 sec)\n",
      ">>> [2025/01/04 09:58:32] Epoch: 186    Loss: 0.013415   (7 sec)\n",
      ">>> [2025/01/04 09:58:39] Epoch: 187    Loss: 0.010105   (7 sec)\n",
      ">>> [2025/01/04 09:58:46] Epoch: 188    Loss: 0.010453   (7 sec)\n",
      ">>> [2025/01/04 09:58:52] Epoch: 189    Loss: 0.010934   (6 sec)\n",
      ">>> [2025/01/04 09:58:59] Epoch: 190    Loss: 0.010723   (7 sec)\n",
      ">>> [2025/01/04 09:59:06] Epoch: 191    Loss: 0.012538   (7 sec)\n",
      ">>> [2025/01/04 09:59:12] Epoch: 192    Loss: 0.011887   (7 sec)\n",
      ">>> [2025/01/04 09:59:19] Epoch: 193    Loss: 0.011965   (7 sec)\n",
      ">>> [2025/01/04 09:59:26] Epoch: 194    Loss: 0.010276   (7 sec)\n",
      ">>> [2025/01/04 09:59:32] Epoch: 195    Loss: 0.009952   (7 sec)\n",
      ">>> [2025/01/04 09:59:39] Epoch: 196    Loss: 0.009100   (7 sec)\n",
      ">>> [2025/01/04 09:59:46] Epoch: 197    Loss: 0.011715   (7 sec)\n",
      ">>> [2025/01/04 09:59:52] Epoch: 198    Loss: 0.009839   (6 sec)\n",
      ">>> [2025/01/04 09:59:59] Epoch: 199    Loss: 0.010688   (7 sec)\n",
      ">>> [2025/01/04 10:00:06] Epoch: 200    Loss: 0.009090   (7 sec)\n"
     ]
    }
   ],
   "source": [
    "## the loss_plot array will be reset many times\n",
    "best_score = 0.\n",
    "history = {'loss_training':[], 'score_validation':[]}\n",
    "for epoch in range(start_epoch, Configs.epochs):\n",
    "    start = time.time()\n",
    "    total_loss = 0.\n",
    "\n",
    "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "        batch_loss, t_loss = trainer.train_step(img_tensor, target, loss_function)\n",
    "        total_loss += t_loss\n",
    "    total_loss = total_loss.numpy() / num_steps\n",
    "    \n",
    "    score = 0.\n",
    "    if do_validation and epoch % 5 == 0:\n",
    "        val_pred = trainer.evaluate(val_img_name, image_features_extract_model)\n",
    "        for x, y in zip(val_smiles, val_pred):\n",
    "            score += I2S_Utils.calc_tanimoto_similarity(x, y)\n",
    "        score /= len(val_smiles)\n",
    "        \n",
    "        if best_score < score:\n",
    "            print(f'checkpoint is updated: {best_score:.3f} -> {score:.3f}')\n",
    "            best_score = score\n",
    "\n",
    "    ## storing the epoch end loss value to plot later\n",
    "    history['loss_training'].append(total_loss)\n",
    "    history['score_validation'].append(score)    \n",
    "    \n",
    "    ckpt_manager.save()\n",
    "    print(f\">>> [{datetime.now().strftime('%Y/%m/%d %H:%M:%S')}] Epoch: {epoch+1}    Loss: {total_loss:.6f}   ({time.time() - start:.0f} sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4088f153-30da-47fe-9118-30f329ff849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "df_history.to_csv(os.path.join('ckpt', f\"history_{Configs.filename_training}.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
